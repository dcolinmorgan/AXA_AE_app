{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amber-license",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.layers import LSTM\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# !pip install shap\n",
    "# import shap\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8481d209-123d-4f73-bd9e-fa5598119bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_sliding1(X, num_steps_x = 2, num_steps_y = 2):\n",
    "    X = pd.DataFrame(X)\n",
    "    X_transformed = [np.array(X.shift(i)) for i in range(num_steps_x + num_steps_y)]\n",
    "    X_transformed = np.dstack(X_transformed)\n",
    "    \n",
    "    # swap time steps and dimensionality axes\n",
    "    X_transformed = np.swapaxes(X_transformed, 1, 2)\n",
    "    # flip time steps axis\n",
    "    X_transformed = np.flip(X_transformed, 1)\n",
    "    X_transformed = X_transformed[(num_steps_x+num_steps_y - 1):]\n",
    "    return X_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "super-there",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_EDdata(input_data_shiftedy,var,n_steps_x,n_steps_y):\n",
    "\n",
    "    # number of time steps for sequence learning\n",
    "    # n_steps_x = 14\n",
    "    # number of time steps for sequence prediction\n",
    "    # n_steps_y = 1\n",
    "\n",
    "    split_at = int(len(input_data_shiftedy) * .8)\n",
    "    val_split_at = int(len(input_data_shiftedy) * .9)\n",
    "\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    # if only prevalence data\n",
    "    input_data_shiftedy = input_data_shiftedy.values.reshape((input_data_shiftedy.shape[0], -1))\n",
    "    input_data_shiftedy[:(split_at + n_steps_x + n_steps_y)] = scaler.fit_transform(\n",
    "        input_data_shiftedy[:(split_at + n_steps_x + n_steps_y)])\n",
    "    # only transform valid and testing sets\n",
    "    input_data_shiftedy[(split_at + n_steps_x + n_steps_y):] = scaler.transform(\n",
    "        input_data_shiftedy[(split_at + n_steps_x + n_steps_y):])\n",
    "\n",
    "\n",
    "    input_data_shiftedy = reshape_sliding1(input_data_shiftedy, \n",
    "                                           num_steps_x = n_steps_x,\n",
    "                                          num_steps_y = n_steps_y)\n",
    "\n",
    "    # train_test_split \n",
    "\n",
    "   \n",
    "    X_train = input_data_shiftedy[:split_at, :n_steps_x, 1:]#data.shape[1]-1]\n",
    "    X_valid = input_data_shiftedy[split_at:val_split_at, :n_steps_x, 1:]#data.shape[1]-1]\n",
    "    X_test = input_data_shiftedy[val_split_at:, :n_steps_x, 1:]#data.shape[1]-1]\n",
    "\n",
    "    Y = np.empty((input_data_shiftedy.shape[0], n_steps_x))\n",
    "    for step_ahead in range(1, n_steps_y + 1):\n",
    "        # print(step_ahead, step_ahead + n_steps_x)\n",
    "        Y = input_data_shiftedy[..., step_ahead:step_ahead + n_steps_x, 0]\n",
    "    Y_train = Y[:split_at, 0:1]\n",
    "    Y_valid = Y[split_at:val_split_at,0:1]\n",
    "    Y_test = Y[val_split_at:,0:1]\n",
    "\n",
    "    print(X_train.shape, Y_train.shape, X_test.shape, Y_test.shape,X_valid.shape, Y_valid.shape)\n",
    "\n",
    "    return X_train,Y_train,X_test,Y_test,X_valid,Y_valid,var\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "d1aa8eea-aa60-46e0-87c4-4a36b8e58b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_EDmdl(X_train,Y_train,X_test,Y_test,X_valid,Y_valid):#,var):\n",
    "    optimizer = keras.optimizers.Adam(clipvalue = 1)\n",
    "    # simplified wavenet\n",
    "    def last_time_step_mse(Y_true, Y_pred):\n",
    "        return keras.metrics.mean_squared_error(Y_true[:, -1], Y_pred[:, -1])\n",
    "\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape = [X_train.shape[1], X_train.shape[2]]))\n",
    "    for rate in (1, 2, 4, 8, 16) * 2:\n",
    "        model.add(keras.layers.Conv1D(filters = 100, kernel_size = 2, padding = \"causal\",\n",
    "                                     activation = \"relu\", dilation_rate = rate))\n",
    "    model.add(keras.layers.Conv1D(filters = 1, kernel_size = 1))\n",
    "    # model.add(keras.layers.LSTM(100))\n",
    "    # model.add(keras.layers.Dense(1))\n",
    "    model.add(keras.layers.Lambda(lambda x: tf.reshape(x, [-1, 14])))\n",
    "    model.add(keras.layers.Dense(1)) ## to collapse all var to predict prevalence alone\n",
    "    model.compile(loss = \"mse\", optimizer = optimizer, metrics = [last_time_step_mse])\n",
    "\n",
    "#     history = model.fit(X_train, Y_train, epochs=30,verbose=0, shuffle=True, validation_data=(X_valid, Y_valid),callbacks = [callback])\n",
    "\n",
    "#     pred = model.predict(X_test)\n",
    "#     keras.backend.clear_session()\n",
    "#     # mse = (mean_squared_error(pred, Y_test))\n",
    "#     print('Test MSE: %.3f' % mse)\n",
    "\n",
    "#     plt.plot(np.double(pred[:, -1]-.5).flatten(), alpha = .5,label='pred')\n",
    "#     plt.plot(np.double(Y_test[:, -1]).flatten(), alpha = .5,label='valid')\n",
    "#     # plt.title(var+'_MSE: '+str(mse))\n",
    "#     plt.legend()\n",
    "#     plt.savefig('edNNtest/'+var+'_mse.png')\n",
    "    # print(model.summary())\n",
    "#     plt.clf()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7bbb89-1504-4357-9c37-9d57bf447efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(X_train,Y_train,X_test,Y_test,X_valid,Y_valid):\n",
    "    # use simple CNN structure\n",
    "    in_shape = ([X_train.shape[1], X_train.shape[2]])\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.ConvLSTM2D(32, kernel_size=(7, 7), padding='valid', return_sequences=True, input_shape=in_shape))\n",
    "    model.add(keras.layers.Activation('relu'))\n",
    "    model.add(keras.layers.MaxPooling3D(pool_size=(1, 2, 2)))\n",
    "    model.add(keras.layers.ConvLSTM2D(64, kernel_size=(5, 5), padding='valid', return_sequences=True))\n",
    "    model.add(keras.layers.MaxPooling3D(pool_size=(1, 2, 2)))\n",
    "    model.add(keras.layers.ConvLSTM2D(96, kernel_size=(3, 3), padding='valid', return_sequences=True))\n",
    "    model.add(keras.layers.Activation('relu'))\n",
    "    model.add(keras.layers.ConvLSTM2D(96, kernel_size=(3, 3), padding='valid', return_sequences=True))\n",
    "    model.add(keras.layers.Activation('relu'))\n",
    "    model.add(keras.layers.ConvLSTM2D(96, kernel_size=(3, 3), padding='valid', return_sequences=True))\n",
    "    model.add(keras.layers.MaxPooling3D(pool_size=(1, 2, 2)))\n",
    "    model.add(keras.layers.Dense(320))\n",
    "    model.add(keras.layers.Activation('relu'))\n",
    "    model.add(keras.layers.Dropout(0.5))\n",
    "\n",
    "    # out_shape = model.output_shape\n",
    "    # print('====Model shape: ', out_shape)\n",
    "    # model.add(Reshape((SequenceLength, out_shape[2] * out_shape[3] * out_shape[4])))\n",
    "    model.add(keras.layers.LSTM(64, return_sequences=False))\n",
    "    model.add(keras.layers.Dropout(0.5))\n",
    "    model.add(keras.layers.Dense(N_CLASSES, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "    # model structure summary\n",
    "    print(model.summary())\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc6d3ed-5501-4500-9db9-ddb5f3d61742",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1712aabf-7c4f-461a-8f14-90678eed516e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1861, 14, 1) (1861, 1) (219, 14, 1) (219, 1) (233, 14, 1) (233, 1)\n",
      "7/7 [==============================] - 0s 6ms/step\n",
      "Test MSE: 0.003\n",
      "(1861, 14, 5) (1861, 1) (219, 14, 5) (219, 1) (233, 14, 5) (233, 1)\n",
      "7/7 [==============================] - 0s 6ms/step\n",
      "Test MSE: 1.321\n",
      "(1861, 14, 2) (1861, 1) (219, 14, 2) (219, 1) (233, 14, 2) (233, 1)\n"
     ]
    }
   ],
   "source": [
    "var_list = []\n",
    "mse_list = []\n",
    "pred_list = pd.DataFrame(columns=['all','poll','ae','prev'])\n",
    "order_list = []\n",
    "x_days=14\n",
    "y_days=1\n",
    "\n",
    "for i in ['prev','poll','ae','all']:\n",
    "    # for SS in ['orig','shuf']:\n",
    "\n",
    "    with open(\"edmond_datasets.pickle\", \"rb\") as handle:\n",
    "        input_data_shiftedy = pickle.load(handle)\n",
    "    # select only n, daily asthma visits and total, daily total AE visits, \n",
    "    # comment out if including air pollution station data\n",
    "    first_col = input_data_shiftedy.n / input_data_shiftedy.total * 1000\n",
    "    input_data_shiftedy.insert(0, \"prevalence\", first_col)\n",
    "    input_data_shiftedy = input_data_shiftedy.drop([\"n\", \"total\", \"y\"], axis = 1)\n",
    "    data=pd.DataFrame(input_data_shiftedy.filter(like='CO_', axis=1).mean(axis=1),columns=['CO'])\n",
    "    data['NO2']=input_data_shiftedy.filter(like='NO2_', axis=1).mean(axis=1)\n",
    "    data['O3']=input_data_shiftedy.filter(like='O3_', axis=1).mean(axis=1)\n",
    "    data['SO2']=input_data_shiftedy.filter(like='SO2_', axis=1).mean(axis=1)\n",
    "    data['CO']=input_data_shiftedy.filter(like='CO_', axis=1).mean(axis=1)\n",
    "    data['FSP']=input_data_shiftedy.filter(like='FSP_', axis=1).mean(axis=1)\n",
    "    data[['prevalence','temp','RelHum']]=input_data_shiftedy[['prevalence','Mean (deg. C)','Mean Relative Humidity (%)']]\n",
    "    # input_data_shiftedy = pd.concat([input_data_shiftedy.n.reset_index(drop = True), \n",
    "    #                         input_data_shiftedy.total.reset_index(drop = True)], axis = 1)\n",
    "    # input_data_shiftedy = input_data_shiftedy[var]\n",
    "    first_column = data.pop('prevalence')\n",
    "    data.insert(0, 'prevalence', first_column)\n",
    "       \n",
    "    if i=='prev':\n",
    "        data=data[['prevalence','prevalence']]\n",
    "    elif i=='ae':\n",
    "        data=data[['prevalence','temp','RelHum']]\n",
    "    elif i =='poll':\n",
    "        data=data[['prevalence','FSP','O3','NO2','SO2','CO']]\n",
    "    elif i =='all':\n",
    "        data=data\n",
    "        \n",
    "        \n",
    "    # n_days=7\n",
    "    if keras.Model:\n",
    "        keras.backend.clear_session()\n",
    "    X_train, train_Y,X_test,Y_test,X_valid,Y_valid,var=load_EDdata(data,i,x_days,y_days)\n",
    "    # print(X_train.shape, train_Y.shape, X_test.shape, Y_test.shape,X_valid.shape, Y_valid.shape)\n",
    "\n",
    "    model=run_EDmdl(X_train, train_Y,X_test,Y_test,X_valid,Y_valid)#,var)\n",
    "    # model=load_model(X_train, train_Y,X_test,Y_test,X_valid,Y_valid)#,var)\n",
    "    callback = keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "    history = model.fit(X_train, Y_train, epochs=30,verbose=0, shuffle=True, validation_data=(X_valid, Y_valid),callbacks = [callback])\n",
    "\n",
    "    pred = model.predict(X_test)\n",
    "    # keras.backend.clear_session()\n",
    "    mse = (mean_squared_error(pred, Y_test))\n",
    "    print('Test MSE: %.3f' % mse)\n",
    "    keras.backend.clear_session()\n",
    "    plt.figure(figsize=(10,8))\n",
    "    plt.plot(np.double(pred[:, -1]).flatten(), alpha = .5,label='pred')\n",
    "    plt.plot(np.double(Y_test[:, -1]).flatten(), alpha = .5,label='valid')\n",
    "    plt.title(var+'_MSE: '+str(mse))\n",
    "    plt.legend()\n",
    "    plt.savefig('edNNtest/'+var+'_mse.png')\n",
    "    plt.clf()\n",
    "    var_list.append(i)\n",
    "    mse_list.append(mse)\n",
    "    pred_list[i]=(pred[:, -1])\n",
    "\n",
    "        \n",
    "\n",
    "df = pd.DataFrame(list(zip(var_list , mse_list)),#,order_list)), \n",
    "           columns =['var', ',mse'])\n",
    "df.to_csv('NNtest/NN_mse.txt',sep='\\t')\n",
    "\n",
    "pred_list['Y_test']=Y_test[:, -1]\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.plot(np.double(pred_list['Y_test']).flatten(), alpha = .5,label='test')\n",
    "plt.plot(np.double(pred_list['all']).flatten(), alpha = .5,label='all mse: '+str(mse_list[0]))\n",
    "plt.plot(np.double(pred_list['poll']).flatten(), alpha = .5,label='poll mse: '+str(mse_list[1]))\n",
    "plt.plot(np.double(pred_list['ae']).flatten(), alpha = .5,label='ae mse: '+str(mse_list[2]))\n",
    "plt.plot(np.double(pred_list['prev']).flatten(), alpha = .5,label='prev mse: '+str(mse_list[3]))\n",
    "\n",
    "plt.title('all_MSE: '+str(mse))\n",
    "plt.legend()\n",
    "# plt.savefig('edNNtest/all_mse.png')\n",
    "# plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374076ec-1a8a-4cf1-8820-21013749964a",
   "metadata": {},
   "outputs": [],
   "source": [
    "VV = data.values\n",
    "groups = [0, 1, 2, 3, 4, 5, 6, 7]\n",
    "i = 1\n",
    "plt.figure(figsize=(10,8))\n",
    "for group in groups:\n",
    "    plt.subplot(len(groups), 1, i)\n",
    "    plt.plot(VV[:, group])\n",
    "    plt.title(data.columns[group], y=0.5, loc='right')\n",
    "    i += 1\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97bfb49f-e895-437b-9c29-9a94f46ae9f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mypy38",
   "language": "python",
   "name": "mypy38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
