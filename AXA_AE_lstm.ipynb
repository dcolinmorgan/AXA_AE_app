{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92a03b9c-b6b7-4351-9e05-44a47941b2ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-08 16:44:55.546038: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-09-08 16:44:55.550701: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /cm/shared/apps/anaconda3-2021-05/lib:/cm/shared/apps/pbspro-ce/19.1.3/lib/\n",
      "2022-09-08 16:44:55.550720: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    "from numpy import concatenate\n",
    "from matplotlib import pyplot\n",
    "import pandas as pd, numpy as np, matplotlib.pyplot as plt\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7785362b-4435-4ad4-b4a7-210e583c7fbd",
   "metadata": {},
   "source": [
    "## inspiration [here](https://machinelearningmastery.com/multivariate-time-series-forecasting-lstms-keras/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49e973a1-da8d-4325-82ce-b1a25f6287f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# convert series to supervised learning\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde6b06b-571e-4d3c-b2c4-5d8b2094a30c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6804e01f-3d93-48b0-967a-ee4d11bef274",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ld_data(data,n_days):\n",
    "\n",
    "    # load dataset\n",
    "    # data = read_csv('pollution.csv', header=0, index_col=0)\n",
    "    values = data.values\n",
    "    # integer encode direction\n",
    "    encoder = LabelEncoder()\n",
    "    # values[:,4] = encoder.fit_transform(values[:,4])\n",
    "    # ensure all data is float\n",
    "    values = values.astype('float32')\n",
    "    # normalize features\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled = scaler.fit_transform(values)\n",
    "    # frame as supervised learning\n",
    "    # reframed = series_to_supervised(scaled, 1, 1)\n",
    "    ...\n",
    "    # specify the number of lag hours\n",
    "    # n_days = 7\n",
    "    n_features = scaled.shape[1]\n",
    "    # frame as supervised learning\n",
    "    reframed = series_to_supervised(scaled, n_days, 1)\n",
    "\n",
    "    # drop columns we don't want to predict\n",
    "    # reframed.drop(reframed.columns[9:], axis=1, inplace=True)\n",
    "\n",
    "    drop=np.arange(n_features+1,(2*n_features),1)\n",
    "    reframed.drop(reframed.columns[drop], axis=1, inplace=True)\n",
    "\n",
    "    # print(reframed.head())\n",
    "\n",
    "    # split into train and test sets\n",
    "    values = reframed.values\n",
    "    n_train_hours = 365 * round((len(data)/365)*.7) #5 #24\n",
    "    train = values[:n_train_hours, :]\n",
    "    test = values[n_train_hours:, :]\n",
    "    # split into input and outputs\n",
    "    train_X, train_y = train[:, :-1], train[:, -1]\n",
    "    test_X, test_y = test[:, :-1], test[:, -1]\n",
    "    # reshape input to be 3D [samples, timesteps, features]\n",
    "    # train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "    # test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "    # print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)\n",
    "\n",
    "    # split into input and outputs\n",
    "    n_obs = n_days * n_features\n",
    "    train_X, train_y = train[:, :n_obs], train[:, -n_features]\n",
    "    test_X, test_y = test[:, :n_obs], test[:, -n_features]\n",
    "    # print(train_X.shape, len(train_X), train_y.shape)\n",
    "    # reshape input to be 3D [samples, timesteps, features]\n",
    "    train_X = train_X.reshape((train_X.shape[0], n_days, n_features))\n",
    "    test_X = test_X.reshape((test_X.shape[0], n_days, n_features))\n",
    "    return train_X, train_y,test_X,test_y,n_features,scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0fd1c334-11cc-433e-96e9-42ae2a440f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_mdl(train_X, train_y,test_X,test_y,YY,var,site,n_days,n_features,scaler):\n",
    "    # design network\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    # fit network\n",
    "    if YY=='shuf':\n",
    "        train_y=np.random.permutation(train_y)\n",
    "    elif YY=='orig':\n",
    "        train_y=train_y\n",
    "\n",
    "    history = model.fit(train_X, train_y, epochs=50, batch_size=72, validation_data=(test_X, test_y), verbose=0, shuffle=True)\n",
    "\n",
    "    # plot history\n",
    "    pyplot.plot(history.history['loss'], label='train')\n",
    "    pyplot.plot(history.history['val_loss'], label='test')\n",
    "    pyplot.legend()\n",
    "    pyplot.title(var+'_'+YY+'_loss_'+site)\n",
    "    # pyplot.show()\n",
    "    plt.savefig('NNtest/'+var+'_'+YY+'_loss_'+site+'.png')\n",
    "    plt.clf()\n",
    "    # make a prediction\n",
    "    yhat = model.predict(test_X)\n",
    "    test_X = test_X.reshape((test_X.shape[0], n_days*n_features))\n",
    "\n",
    "    # invert scaling for forecast\n",
    "    inv_yhat = concatenate((yhat, test_X[:, -(n_features-1):]), axis=1)\n",
    "    inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "    inv_yhat = inv_yhat[:,0]\n",
    "    # invert scaling for actual\n",
    "    test_y = test_y.reshape((len(test_y), 1))\n",
    "    inv_y = concatenate((test_y, test_X[:, -(n_features-1):]), axis=1)\n",
    "    inv_y = scaler.inverse_transform(inv_y)\n",
    "    inv_y = inv_y[:,0]\n",
    "\n",
    "    # calculate RMSE\n",
    "    mse = (mean_squared_error(inv_y, inv_yhat))\n",
    "    # print('Test MSE: %.3f' % mse)\n",
    "\n",
    "    plt.plot(np.rint(inv_y), alpha = .5,label='pred')\n",
    "    plt.plot(np.double(inv_yhat), alpha = .5,label='valid')\n",
    "    plt.title(site+'_'+var+'_'+YY+ 'MSE: '+str(mse))\n",
    "    plt.legend()\n",
    "    plt.savefig('NNtest/'+site+'_'+var+'_'+YY+'_mse.png')\n",
    "    plt.clf()\n",
    "    return mse\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4bd94a7-bb67-485f-90b4-1c302e7976ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 2ms/step\n",
      "QEH_all_origMSE: 0.0018554541\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "QEH_all_shufMSE: 2.8838868\n",
      "25/25 [==============================] - 0s 2ms/step\n",
      "QEH_ae_origMSE: 0.0037106762\n",
      "25/25 [==============================] - 0s 2ms/step\n",
      "QEH_ae_shufMSE: 3.5277917\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "QEH_poll_origMSE: 0.0078683235\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "QEH_poll_shufMSE: 2.916048\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "var_list = []\n",
    "mse_list = []\n",
    "site_list = []\n",
    "order_list = []\n",
    "\n",
    "for i in ['all','ae','poll']:\n",
    "    for SS in ['orig','shuf']:\n",
    "        d6=pd.read_parquet('~/run/AXA_AE_app/AE_AXA_poll-ae.parquet')#, compression='GZIP')#.mode('overwrite')\n",
    "        # site=np.random.randint(0,len(np.unique(d6['cd9_loc'])))\n",
    "        # site=np.unique(d6['cd9_loc'])[site]\n",
    "        # data=d6[d6['cd9_loc']==site]\n",
    "        # site=[ s[0] for s in site.split() ]\n",
    "\n",
    "        data=d6[d6['cd9_loc']=='Queen Elizabeth Hospital']\n",
    "        site='QEH'\n",
    "        \n",
    "        data=data.groupby(['cd9_loc','date']).agg('mean')[['pm25','pm10','o3','no2','so2','co','age','sex','diag1']]\n",
    "        data.age=np.round(data.age)\n",
    "        data.sex=np.round(data.sex)\n",
    "        # values = dataset.values\n",
    "        first_column = data.pop('diag1')\n",
    "        data.insert(0, 'diag1', first_column)\n",
    "        print\n",
    "        if i=='all':\n",
    "            data=data\n",
    "        elif i=='ae':\n",
    "            data=data[['diag1','age','sex']]\n",
    "        elif i =='poll':\n",
    "            data.drop(['age','sex'],axis=1,inplace=True)\n",
    "        n_days=7\n",
    "        train_X, train_y,test_X,test_y,n_features,scaler=ld_data(data,n_days)\n",
    "        mse=run_mdl(train_X, train_y,test_X,test_y,SS,i,site,n_days,n_features,scaler)\n",
    "        \n",
    "        var_list.append(i)\n",
    "        mse_list.append(mse)\n",
    "        site_list.append(site)\n",
    "        order_list.append(SS)\n",
    "        print(site+'_'+i+'_'+SS+ 'MSE: '+str(mse))\n",
    "        \n",
    "df = pd.DataFrame(list(zip(var_list , mse_list,site_list,order_list)), \n",
    "           columns =['var', ',mse','site','order'])\n",
    "\n",
    "df.to_csv('NNtest/NN_mse.txt',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67ccf981-e997-41dd-8d7f-e6a9f8a7f0b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var</th>\n",
       "      <th>,mse</th>\n",
       "      <th>site</th>\n",
       "      <th>order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>all</td>\n",
       "      <td>0.001855</td>\n",
       "      <td>QEH</td>\n",
       "      <td>orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>all</td>\n",
       "      <td>2.883887</td>\n",
       "      <td>QEH</td>\n",
       "      <td>shuf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ae</td>\n",
       "      <td>0.003711</td>\n",
       "      <td>QEH</td>\n",
       "      <td>orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ae</td>\n",
       "      <td>3.527792</td>\n",
       "      <td>QEH</td>\n",
       "      <td>shuf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>poll</td>\n",
       "      <td>0.007868</td>\n",
       "      <td>QEH</td>\n",
       "      <td>orig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>poll</td>\n",
       "      <td>2.916048</td>\n",
       "      <td>QEH</td>\n",
       "      <td>shuf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    var      ,mse site order\n",
       "0   all  0.001855  QEH  orig\n",
       "1   all  2.883887  QEH  shuf\n",
       "2    ae  0.003711  QEH  orig\n",
       "3    ae  3.527792  QEH  shuf\n",
       "4  poll  0.007868  QEH  orig\n",
       "5  poll  2.916048  QEH  shuf"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05c0229-9fb8-4f63-bf5f-b281d37643d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mypy38",
   "language": "python",
   "name": "mypy38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
