{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dcolinmorgan/AXA_AE_app/blob/main/DM_AXA_AE_JAX_jraph.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUxD4gOd-AuO"
      },
      "source": [
        "## Setup: Install and Import libraries\n",
        "[modified from tutorial HERE](https://github.com/deepmind/educational/blob/master/colabs/summer_schools/intro_to_graph_nets_tutorial_with_jraph.ipynb) |  \n",
        "[merge with this](https://keras.io/examples/timeseries/) |   [also this](https://github.com/deepmind/graph_nets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "OyH_VgjW7Bp3"
      },
      "outputs": [],
      "source": [
        "# !pip install git+https://github.com/deepmind/jraph.git\n",
        "# !pip install flax\n",
        "# !pip install dm-haiku"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "RJm7y6GH3WyB"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "%matplotlib inline\n",
        "import functools,glob,jax,jraph,optax,pickle,flax,os,collections\n",
        "import matplotlib.pyplot as plt\n",
        "import jax.numpy as jnp\n",
        "import jax.tree_util as tree\n",
        "import haiku as hk\n",
        "import absl as app\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "import pandas as pd\n",
        "from geopy.geocoders import Nominatim\n",
        "import geopy.distance\n",
        "\n",
        "from typing import Any, Callable, Dict, List, Optional, Tuple\n",
        "\n",
        "StatefulField = collections.namedtuple(\"StatefulField\", [\"embedding\", \"state\"])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5SE5DQoXWQJR"
      },
      "source": [
        "Let's load the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !wget https://github.com/dcolinmorgan/AXA_AE_app/raw/main/axa_p.zip\n",
        "# !7z x /content/axa_p.zip\n",
        "# !git clone https://github.com/dcolinmorgan/aqi-stations-scraper.git\n",
        "\n",
        "df2=pd.read_parquet('/content/AE_AXA_dat_full.parquet')\n",
        "\n",
        "\n",
        "# list_a = ['pneumonia', 'COPD','asthma','resp','lung','pulm']#,'~Cancer']\n",
        "# list_b = ['Cancer']\n",
        "df2.columns=['pat_id','cd9_loc','sess','sex','age','cd9_code','mini_loc','loc1','date','tmp','diag1','diag2','tmp']\n",
        "\n",
        "# df2=df[df['diag1'].isin(list_a)]\n",
        "# df2 = df[df['diag1'].str.contains('|'.join(list_a))]\n",
        "\n",
        "# df.diag1, df.diag2 = np.where(df.diag1.str.contains('None'), [df.diag2, df.diag1], [df.diag1, df.diag2])\n",
        "# del df['sess'], df['tmp'], df['diag2']\n",
        "# df=df[~df['diag1'].isna()]\n",
        "\n",
        "# df2 = df[df['diag1'].str.contains('|'.join(list_a))]\n",
        "\n",
        "df2.replace({'RH':'Ruttonjee Hospital'},inplace=True)\n",
        "df2.replace({'PYN':'Pamela Youde Nethersole Eastern Hospital'},inplace=True)\n",
        "df2.replace({'QEH':'Queen Elizabeth Hospital'},inplace=True)\n",
        "df2.replace({'CMC':'Caritas Medical Centre'},inplace=True)\n",
        "df2.replace({'KWH':'Kwong Wah Hospital'},inplace=True)\n",
        "df2.replace({'TMH':'Tuen Mun Hospital'},inplace=True)\n",
        "df2.replace({'PWH':'Prince of Wales Hospital'},inplace=True)\n",
        "df2.replace({'NDH':'North District Hospital'},inplace=True)\n",
        "df2.replace({'YCH':'Yan Chai Hospital'},inplace=True)\n",
        "df2.replace({'UCH':'United Christian Hospital'},inplace=True)\n",
        "df2.replace({'QMH':'Queen Mary Hospital'},inplace=True)\n",
        "df2.replace({'PWH':'Princess Margaret Hospital'},inplace=True)\n",
        "df2.replace({'POH':'Pok Oi Hospital'},inplace=True)\n",
        "df2.replace({'TKO':'Tseung Kwan O Hospital'},inplace=True)\n",
        "df2.replace({'AHN':'Alice Ho Miu Ling Nethersole Hospital'},inplace=True)\n",
        "df2.replace({'SJH':'St. John Hospital'},inplace=True)\n",
        "df2.replace({'NLT':'North Lantau Hospital'},inplace=True)\n",
        "df2.replace({'TSH':'Tang Shiu Kin Hospital'},inplace=True)\n",
        "df2.replace({'PMH':'Princess Margaret Hospital'},inplace=True)\n",
        "\n",
        "\n",
        "#organize\n",
        "cc=pd.DataFrame()#(columns=['date','pm25','pm10','o3','no2','so2','co','loc'])\n",
        "files=glob.glob('/content/aqi-stations-scraper/data/japan-aqi/*')\n",
        "for file in files:\n",
        "    data=pd.read_csv(file,sep=' |,')\n",
        "    data['loc1']=os.path.basename(file).split(',')[0]\n",
        "    cc=cc.append(data)\n",
        "\n",
        "data2=cc[['date','pm25','pm10','o3','no2','so2','co','loc1']]\n",
        "data2['loc1']=data2['loc1'].str.upper().replace({'-':' '},regex=True)\n",
        "data2['date']=pd.to_datetime(data2['date'])\n",
        "\n",
        "geolocator = Nominatim(user_agent=\"example app\")\n",
        "df_loc=pd.DataFrame(columns=['lat','long','name'])\n",
        "for ii,i in enumerate(pd.unique(df2['cd9_loc'])):\n",
        "    a,b,c=geolocator.geocode(str(i)+\", Hong Kong\").point\n",
        "    df_loc[ii]=[a,b,i]\n",
        "df_loc=df_loc.transpose()\n",
        "df_loc.columns=['lat','long','name']\n",
        "df_loc=df_loc[3:]\n",
        "\n",
        "\n",
        "data2.replace('CENTRALNAYA STR','central',inplace=True)\n",
        "data2.replace('SOUTHERN','southern island',inplace=True)\n",
        "data2.replace('SOUTHERN PART OF CHENGYANG DISTRICT','chengyang district',inplace=True)\n",
        "\n",
        "data_loc=pd.DataFrame(columns=['lat','long','name'])\n",
        "for ii,i in enumerate(pd.unique(data2['loc1'])):\n",
        "    try:\n",
        "        a,b,c=geolocator.geocode(str(i)+\", Hong Kong\").point\n",
        "    except AttributeError:\n",
        "        print('no location data for: '+str(i))\n",
        "    data_loc[ii]=[a,b,i]\n",
        "data_loc=data_loc.transpose()\n",
        "data_loc.columns=['lat','long','name']\n",
        "data_loc=data_loc[3:]\n",
        "\n",
        "data_loc=data_loc[~data_loc.duplicated(['lat','long'],keep='first')]\n",
        "data_loc.reset_index(inplace=True)\n",
        "\n",
        "data_loc=df_loc.append(data_loc)[['lat','long','name']]\n",
        "2\n",
        "data_loc.reset_index(inplace=True)\n",
        "\n",
        "\n",
        "# geopy DOES use latlon configuration\n",
        "data_loc['latlon'] = list(zip(data_loc['lat'], data_loc['long']))\n",
        "square = pd.DataFrame(\n",
        "    np.zeros((data_loc.shape[0], data_loc.shape[0])),\n",
        "    index=data_loc.index, columns=data_loc.index\n",
        ")\n",
        "\n",
        "# replacing distance.vicenty with distance.distance\n",
        "def get_distance(col):\n",
        "    end = data_loc.loc[col.name, 'latlon']\n",
        "    return data_loc['latlon'].apply(geopy.distance.distance,\n",
        "                              args=(end,),\n",
        "                              ellipsoid='WGS-84'\n",
        "                             )\n",
        "\n",
        "distances = square.apply(get_distance, axis=1).T\n",
        "\n",
        "data_loc['src']=data_loc['name']\n",
        "data_loc['dst']=data_loc['name']\n",
        "\n",
        "# np.sum((distances<5)*1)\n",
        "D_D=pd.DataFrame((distances<5)*1)\n",
        "D_D.index=data_loc['src']\n",
        "D_D.columns=data_loc['dst']\n",
        "\n",
        "E_E=pd.DataFrame(D_D.stack())#.reset_index(inplace=True)\n",
        "# E_E.rename=['source','target']#.reset_index(inplace=True)#.rename(columns={'level_0':'Source','level_1':'Target', 0:'Weight'})\n",
        "E_E.reset_index(inplace=True)#\n",
        "distance_mat=E_E[E_E[0]>0]\n",
        "\n",
        "distance=distances\n",
        "distance.index=data_loc['src']\n",
        "distance.columns=data_loc['dst']\n",
        "distance=pd.DataFrame(distance.stack())\n",
        "distance.reset_index(inplace=True)\n",
        "\n",
        "#prepare for TF\n",
        "\n",
        "distances=distances.astype(str) # df.astype(np.float64)#lues.as_int#('int')#.to_numpy()\n",
        "distances=distances.replace('km', '', regex=True)\n",
        "distances=distances.astype(np.float64)\n",
        "\n",
        "distances.to_numpy()"
      ],
      "metadata": {
        "id": "Zt_f14MEbPxb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e416c96-d994-405f-f0fa-817aa39ed781"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py:311: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
            "  return func(*args, **kwargs)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:51: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:5244: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  method=method,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "no location data for: NORTH KHAYAM\n",
            "no location data for: NORTHWEST WATER COMPANY\n",
            "no location data for: NORTH WEST UNIVERSITY VAAL CAMPUS\n",
            "no location data for: chengyang district\n",
            "no location data for: NORTH CHINA INSTITUTE OF AEROSPACE\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.        ,  6.39306762,  3.72494369, ..., 11.64291594,\n",
              "         5.01482076,  6.67098176],\n",
              "       [ 6.39306762,  0.        ,  7.73190544, ...,  9.32175221,\n",
              "         8.86007694,  4.8676185 ],\n",
              "       [ 3.72494369,  7.73190544,  0.        , ...,  9.2757466 ,\n",
              "         1.34718089,  5.29547719],\n",
              "       ...,\n",
              "       [11.64291594,  9.32175221,  9.2757466 , ...,  0.        ,\n",
              "         9.10315234,  5.17491574],\n",
              "       [ 5.01482076,  8.86007694,  1.34718089, ...,  9.10315234,\n",
              "         0.        ,  5.80843504],\n",
              "       [ 6.67098176,  4.8676185 ,  5.29547719, ...,  5.17491574,\n",
              "         5.80843504,  0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### *n.b. set graph to share lung scores (binary) based on proxmity (ie share health scores to weather regions)*"
      ],
      "metadata": {
        "id": "1r4kiJ38ERDV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "GS1d=(df2.pivot_table(values='diag1', index='date', columns='cd9_loc', aggfunc='count').fillna(0).iloc[0].values)\n",
        "GS1d=(np.repeat(GS1d,2))\n",
        "# GS1d=GS1d[:-1]\n",
        "GS1d=(GS1d>0)*1\n",
        "GS1d"
      ],
      "metadata": {
        "id": "uZSMpZtL8UL9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f04696e3-8a5d-4b76-c623-fa0f12d44046"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCZI26T9Q2vy"
      },
      "source": [
        "Training and evaluation code:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "e7q5ySSmVL3x"
      },
      "outputs": [],
      "source": [
        "def convert_jraph_to_networkx_graph(jraph_graph: jraph.GraphsTuple) -> nx.Graph:\n",
        "  nodes, edges, receivers, senders, _, _, _ = jraph_graph\n",
        "  nx_graph = nx.DiGraph()\n",
        "  if nodes is None:\n",
        "    for n in range(jraph_graph.n_node[0]):\n",
        "      nx_graph.add_node(n)\n",
        "  else:\n",
        "    for n in range(jraph_graph.n_node[0]):\n",
        "      nx_graph.add_node(n, node_feature=nodes[n])\n",
        "  if edges is None:\n",
        "    for e in range(jraph_graph.n_edge[0]):\n",
        "      nx_graph.add_edge(int(senders[e]), int(receivers[e]))\n",
        "  else:\n",
        "    for e in range(jraph_graph.n_edge[0]):\n",
        "      nx_graph.add_edge(\n",
        "          int(senders[e]), int(receivers[e]), edge_feature=edges[e])\n",
        "  return nx_graph\n",
        "\n",
        "\n",
        "def draw_jraph_graph_structure(jraph_graph: jraph.GraphsTuple) -> None:\n",
        "  nx_graph = convert_jraph_to_networkx_graph(jraph_graph)\n",
        "  pos = nx.spring_layout(nx_graph)\n",
        "  nx.draw(\n",
        "      nx_graph, pos=pos, with_labels=True, node_size=500, font_color='yellow')\n",
        "  \n",
        "def get_zacharys_karate_club(s_graph) -> jraph.GraphsTuple:\n",
        "  \"\"\"Returns GraphsTuple representing Zachary's karate club.\"\"\"\n",
        "\n",
        "  # social_graph += [(edge[1], edge[0]) for edge in social_graph]\n",
        "  n_nodes = np.max(s_graph)+1\n",
        "\n",
        "\n",
        "  return jraph.GraphsTuple(\n",
        "      n_node=jnp.asarray([n_nodes]),\n",
        "      n_edge=jnp.asarray([len(s_graph)]),\n",
        "      # One-hot encoding for nodes, i.e. argmax(nodes) = node index.\n",
        "      nodes=jnp.eye(n_nodes),\n",
        "      # No edge features.\n",
        "      edges=jnp.asarray(s_graph),#None,\n",
        "      globals=None,\n",
        "      senders=jnp.asarray([edge[0] for edge in s_graph]),\n",
        "      receivers=jnp.asarray([edge[1] for edge in s_graph]))\n",
        "\n",
        "def get_ground_truth_assignments_for_zacharys_karate_club(GS1d) -> jnp.ndarray:\n",
        "  \"\"\"Returns ground truth assignments for Zachary's karate club.\"\"\"\n",
        "  return jnp.array(GS1d)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "RyJk-Mq7EKoU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66e9dcd4-ece6-4d65-e395-6d8362a5c334"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
          ]
        }
      ],
      "source": [
        "distances = square.apply(get_distance, axis=1).T\n",
        "D_D=pd.DataFrame((distances<5)*1)\n",
        "D_D.index=np.arange(0,D_D.shape[1])#data_loc['src']\n",
        "D_D.columns=np.arange(0,D_D.shape[1])#data_loc['dst']\n",
        "\n",
        "E_E=pd.DataFrame(D_D.stack())#.reset_index(inplace=True)\n",
        "E_E.reset_index(inplace=True)#\n",
        "# distance#_mat=E_E[E_E[0]>0]\n",
        "E_E=E_E[E_E['level_0']!=E_E['level_1']]\n",
        "s_graph=E_E[E_E[0]>0][['level_0','level_1']].to_numpy()#=distance_mat[['level_0','level_1']].to_numpy()\n",
        "# n_nodes=36\n",
        "\n",
        "graph = get_zacharys_karate_club(s_graph)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "1n1kCuqtkvfm"
      },
      "outputs": [],
      "source": [
        "# def optimize_club(network: hk.Transformed, num_steps: int) -> jnp.ndarray:\n",
        "#   \"\"\"Solves the karate club problem by optimizing the assignments of students.\"\"\"\n",
        "#   zacharys_karate_club = get_zacharys_karate_club(s_graph)\n",
        "#   labels = get_ground_truth_assignments_for_zacharys_karate_club(GS1d)\n",
        "#   params = network.init(jax.random.PRNGKey(42), zacharys_karate_club)\n",
        "#   paramsA=params\n",
        "@jax.jit\n",
        "def predict(params: hk.Params) -> jnp.ndarray:\n",
        "  decoded_graph = network.apply(params, zacharys_karate_club)\n",
        "  return jnp.argmax(decoded_graph.nodes, axis=1)\n",
        "\n",
        "@jax.jit\n",
        "def prediction_loss(params: hk.Params) -> jnp.ndarray:\n",
        "  decoded_graph = network.apply(params, zacharys_karate_club)\n",
        "  # We interpret the decoded nodes as a pair of logits for each node.\n",
        "  log_prob = jax.nn.log_softmax(decoded_graph.nodes)\n",
        "  # The only two assignments we know a-priori are those of Mr. Hi (Node 0)\n",
        "  # and John A (Node 33).\n",
        "  return -(log_prob[0, 0] + log_prob[33, 1])\n",
        "\n",
        "# opt_init, opt_update = optax.adam(1e-2)\n",
        "# opt_state = opt_init(params)\n",
        "\n",
        "@jax.jit\n",
        "def update(params: hk.Params, opt_state) -> Tuple[hk.Params, Any]:\n",
        "  \"\"\"Returns updated params and state.\"\"\"\n",
        "  g = jax.grad(prediction_loss)(params)\n",
        "  updates, opt_state = opt_update(g, opt_state)\n",
        "  return optax.apply_updates(params, updates), opt_state\n",
        "\n",
        "@jax.jit\n",
        "def accuracy(params: hk.Params) -> jnp.ndarray:\n",
        "  decoded_graph = network.apply(params, zacharys_karate_club)\n",
        "  return jnp.mean(jnp.argmax(decoded_graph.nodes, axis=1) == labels)\n",
        "\n",
        "# for step in range(num_steps):\n",
        "#   print(f\"step {step} accuracy {accuracy(params).item():.2f}\")\n",
        "#   params, opt_state = update(params, opt_state)\n",
        "\n",
        "# return predict(params),paramsA,zacharys_karate_club"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "KJqT6mjgBBmQ"
      },
      "outputs": [],
      "source": [
        "def add_self_edges_fn(receivers: jnp.ndarray, senders: jnp.ndarray,\n",
        "                      total_num_nodes: int) -> Tuple[jnp.ndarray, jnp.ndarray]:\n",
        "  \"\"\"Adds self edges. Assumes self edges are not in the graph yet.\"\"\"\n",
        "  receivers = jnp.concatenate((receivers, jnp.arange(total_num_nodes)), axis=0)\n",
        "  senders = jnp.concatenate((senders, jnp.arange(total_num_nodes)), axis=0)\n",
        "  return receivers, senders\n",
        "\n",
        "\n",
        "# GAT implementation adapted from https://github.com/deepmind/jraph/blob/master/jraph/_src/models.py#L442.\n",
        "def GAT(attention_query_fn: Callable,\n",
        "        attention_logit_fn: Callable,\n",
        "        node_update_fn: Optional[Callable] = None,\n",
        "        add_self_edges: bool = True) -> Callable:\n",
        "  \"\"\"Returns a method that applies a Graph Attention Network layer.\n",
        "\n",
        "  Graph Attention message passing as described in\n",
        "  https://arxiv.org/pdf/1710.10903.pdf. This model expects node features as a\n",
        "  jnp.array, may use edge features for computing attention weights, and\n",
        "  ignore global features. It does not support nests.\n",
        "  Args:\n",
        "    attention_query_fn: function that generates attention queries from sender\n",
        "      node features.\n",
        "    attention_logit_fn: function that converts attention queries into logits for\n",
        "      softmax attention.\n",
        "    node_update_fn: function that updates the aggregated messages. If None, will\n",
        "      apply leaky relu and concatenate (if using multi-head attention).\n",
        "\n",
        "  Returns:\n",
        "    A function that applies a Graph Attention layer.\n",
        "  \"\"\"\n",
        "  # pylint: disable=g-long-lambda\n",
        "  if node_update_fn is None:\n",
        "    # By default, apply the leaky relu and then concatenate the heads on the\n",
        "    # feature axis.\n",
        "    node_update_fn = lambda x: jnp.reshape(\n",
        "        jax.nn.leaky_relu(x), (x.shape[0], -1))\n",
        "\n",
        "  def _ApplyGAT(graph: jraph.GraphsTuple) -> jraph.GraphsTuple:\n",
        "    \"\"\"Applies a Graph Attention layer.\"\"\"\n",
        "    nodes, edges, receivers, senders, _, _, _ = graph\n",
        "    # Equivalent to the sum of n_node, but statically known.\n",
        "    try:\n",
        "      sum_n_node = nodes.shape[0]\n",
        "    except IndexError:\n",
        "      raise IndexError('GAT requires node features')\n",
        "\n",
        "    # Pass nodes through the attention query function to transform\n",
        "    # node features, e.g. with an MLP.\n",
        "    nodes = attention_query_fn(nodes)\n",
        "\n",
        "    total_num_nodes = tree.tree_leaves(nodes)[0].shape[0]\n",
        "    if add_self_edges:\n",
        "      # We add self edges to the senders and receivers so that each node\n",
        "      # includes itself in aggregation.\n",
        "      receivers, senders = add_self_edges_fn(receivers, senders,\n",
        "                                             total_num_nodes)\n",
        "\n",
        "    # We compute the softmax logits using a function that takes the\n",
        "    # embedded sender and receiver attributes.\n",
        "    sent_attributes = nodes[senders]\n",
        "    received_attributes = nodes[receivers]\n",
        "    att_softmax_logits = attention_logit_fn(sent_attributes,\n",
        "                                            received_attributes, edges)\n",
        "\n",
        "    # Compute the attention softmax weights on the entire tree.\n",
        "    att_weights = jraph.segment_softmax(\n",
        "        att_softmax_logits, segment_ids=receivers, num_segments=sum_n_node)\n",
        "\n",
        "    # Apply attention weights.\n",
        "    messages = sent_attributes * att_weights\n",
        "    # Aggregate messages to nodes.\n",
        "    nodes = jax.ops.segment_sum(messages, receivers, num_segments=sum_n_node)\n",
        "\n",
        "    # Apply an update function to the aggregated messages.\n",
        "    nodes = node_update_fn(nodes)\n",
        "\n",
        "    return graph._replace(nodes=nodes)\n",
        "\n",
        "  # pylint: enable=g-long-lambda\n",
        "  return _ApplyGAT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "jUXJcRnVMr4X"
      },
      "outputs": [],
      "source": [
        "def gat_definition(graph: jraph.GraphsTuple) -> jraph.GraphsTuple:\n",
        "  \"\"\"Defines a GAT network for the karate club node classification task.\n",
        "\n",
        "  Args:\n",
        "    graph: GraphsTuple the network processes.\n",
        "\n",
        "  Returns:\n",
        "    output graph with updated node values.\n",
        "  \"\"\"\n",
        "\n",
        "  def _attention_logit_fn(sender_attr: jnp.ndarray, receiver_attr: jnp.ndarray,\n",
        "                          edges: jnp.ndarray) -> jnp.ndarray:\n",
        "    del edges\n",
        "    x = jnp.concatenate((sender_attr, receiver_attr), axis=1)\n",
        "    return hk.Linear(1)(x)\n",
        "\n",
        "  gn = GAT(\n",
        "      attention_query_fn=lambda n: hk.Linear(8)(n),\n",
        "      attention_logit_fn=_attention_logit_fn,\n",
        "      node_update_fn=None,\n",
        "      add_self_edges=True)\n",
        "  graph = gn(graph)\n",
        "\n",
        "  gn = GAT(\n",
        "      attention_query_fn=lambda n: hk.Linear(8)(n),\n",
        "      attention_logit_fn=_attention_logit_fn,\n",
        "      node_update_fn=hk.Linear(2),\n",
        "      add_self_edges=True)\n",
        "  graph = gn(graph)\n",
        "\n",
        "\n",
        "  return graph\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# StatefulField = collections.namedtuple(\"StatefulField\", [\"embedding\", \"state\"])\n",
        "\n",
        "def network_definition(graph: jraph.GraphsTuple) -> jraph.ArrayTree:\n",
        "# def LSTM(graph: jraph.GraphsTuple) -> jraph.ArrayTree:\n",
        "  \"\"\"`InteractionNetwork` with an LSTM in the edge update.\"\"\"\n",
        "  def _attention_logit_fn(sender_nodes: jnp.ndarray, receiver_nodes: jnp.ndarray,\n",
        "                            edges: jnp.ndarray) -> jnp.ndarray:\n",
        "      del edges\n",
        "      x = jnp.concatenate((sender_nodes, receiver_nodes), axis=1)\n",
        "      return hk.Linear(1)(x)\n",
        "\n",
        "  gn = GAT(\n",
        "      attention_query_fn=lambda n: hk.Linear(8)(n),\n",
        "      attention_logit_fn=_attention_logit_fn,\n",
        "      node_update_fn=None,\n",
        "      add_self_edges=True)\n",
        "  graph = gn(graph)\n",
        "\n",
        "  gn = GAT(\n",
        "      attention_query_fn=lambda n: hk.Linear(8)(n),\n",
        "      attention_logit_fn=_attention_logit_fn,\n",
        "      node_update_fn=hk.Linear(2),\n",
        "      add_self_edges=True)\n",
        "  graph = gn(graph)\n",
        "\n",
        "  # LSTM that will keep a memory of the inputs to the edge model.\n",
        "  edge_fn_lstm = hk.LSTM(128)\n",
        "\n",
        "  # MLPs used in the edge and the node model. Note that in this instance\n",
        "  # the output size matches the input size so the same model can be run\n",
        "  # iteratively multiple times. In a real model, this would usually be achieved\n",
        "  # by first using an encoder in the input data into a common `EMBEDDING_SIZE`.\n",
        "  edge_fn_mlp = hk.nets.MLP([128,32])\n",
        "  node_fn_mlp = hk.nets.MLP([128,32])\n",
        "\n",
        "  # Initialize the edge features to contain both the input edge embedding\n",
        "  # and initial LSTM state. Note for the nodes we only have an embedding since\n",
        "  # in this example nodes do not use a `node_fn_lstm`, but for analogy, we\n",
        "  # still put it in a `StatefulField`.\n",
        "  graph = graph._replace(\n",
        "      edges=StatefulField(\n",
        "          embedding=graph.edges,\n",
        "          state=edge_fn_lstm.initial_state(graph.edges.shape[0])),\n",
        "      nodes=StatefulField(embedding=graph.nodes, state=None),\n",
        "  )\n",
        "\n",
        "  def update_edge_fn(edges, sender_nodes, receiver_nodes):\n",
        "    # We will run an LSTM memory on the inputs first, and then\n",
        "    # process the output of the LSTM with an MLP.\n",
        "    edge_inputs = jnp.concatenate([edges.embedding,\n",
        "                                   sender_nodes.embedding,\n",
        "                                   receiver_nodes.embedding], axis=-1)\n",
        "    lstm_output, updated_state = edge_fn_lstm(edge_inputs, edges.state)\n",
        "    updated_edges = StatefulField(\n",
        "        embedding=edge_fn_mlp(lstm_output), state=updated_state,\n",
        "    )\n",
        "    return updated_edges\n",
        "\n",
        "  def update_node_fn(nodes, received_edges):\n",
        "    # Note `received_edges.state` will also contain the aggregated state for\n",
        "    # all received edges, which we may choose to use in the node update.\n",
        "    node_inputs = jnp.concatenate(\n",
        "        [nodes.embedding, received_edges.embedding], axis=-1)\n",
        "    updated_nodes = StatefulField(\n",
        "        embedding=node_fn_mlp(node_inputs),\n",
        "        state=None)\n",
        "    return updated_nodes\n",
        "\n",
        "\n",
        "  recurrent_graph_network = jraph.InteractionNetwork(\n",
        "      update_edge_fn=update_edge_fn,\n",
        "      update_node_fn=update_node_fn)\n",
        "\n",
        "  # Apply the model recurrently for 10 message passing steps.\n",
        "  # If instead we intended to use the LSTM to process a sequence of features\n",
        "  # for each node/edge, here we would select the corresponding inputs from the\n",
        "  # sequence along the sequence axis of the nodes/edges features to build the\n",
        "  # correct input graph for each step of the iteration.\n",
        "  num_message_passing_steps = 10\n",
        "  for _ in range(num_message_passing_steps):\n",
        "    graph = recurrent_graph_network(graph)\n",
        "\n",
        "  return graph"
      ],
      "metadata": {
        "id": "et0xkX56M97R"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "TEHco8n-Mr4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "outputId": "b62c5bda-064c-4c22-eca6-eafd88506d32"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-c79d1eb15823>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mzacharys_karate_club\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_zacharys_karate_club\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_ground_truth_assignments_for_zacharys_karate_club\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGS1d\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPRNGKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzacharys_karate_club\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mparamsA\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/haiku/_src/transform.py\u001b[0m in \u001b[0;36minit_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0minit_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m     \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m       raise ValueError(\"If your transformed function uses `hk.{get,set}_state` \"\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/haiku/_src/transform.py\u001b[0m in \u001b[0;36minit_fn\u001b[0;34m(rng, *args, **kwargs)\u001b[0m\n\u001b[1;32m    333\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrng\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrng\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m         \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnexpectedTracerError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnexpectedTracerError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munexpected_tracer_hint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-665aa7a3651c>\u001b[0m in \u001b[0;36mnetwork_definition\u001b[0;34m(graph)\u001b[0m\n\u001b[1;32m     79\u001b[0m   \u001b[0mnum_message_passing_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_message_passing_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m     \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecurrent_graph_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jraph/_src/models.py\u001b[0m in \u001b[0;36m_ApplyGraphNet\u001b[0;34m(graph)\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mupdate_edge_fn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m       edges = update_edge_fn(edges, sent_attributes, received_attributes,\n\u001b[0;32m--> 183\u001b[0;31m                              global_edge_attributes)\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mattention_logit_fn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jraph/_src/models.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(e, s, r, g)\u001b[0m\n\u001b[1;32m    285\u001b[0m   \u001b[0;31m# An InteractionNetwork edge function does not have global feature inputs,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m   \u001b[0;31m# so we filter the passed global argument in the GraphNetwork.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m   \u001b[0mwrapped_update_edge_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mupdate_edge_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m   \u001b[0;31m# Similarly, we wrap the update_node_fn to ensure only the expected\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-665aa7a3651c>\u001b[0m in \u001b[0;36mupdate_edge_fn\u001b[0;34m(edges, sender_nodes, receiver_nodes)\u001b[0m\n\u001b[1;32m     51\u001b[0m                                    \u001b[0msender_nodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m                                    receiver_nodes.embedding], axis=-1)\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0mlstm_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdated_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0medge_fn_lstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medges\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m     updated_edges = StatefulField(\n\u001b[1;32m     55\u001b[0m         \u001b[0membedding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0medge_fn_mlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupdated_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/haiku/_src/module.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    419\u001b[0m           \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstateful\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocal_module_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 421\u001b[0;31m       \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m       \u001b[0;31m# Module names are set in the constructor. If `f` is the constructor then\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/haiku/_src/module.py\u001b[0m in \u001b[0;36mrun_interceptors\u001b[0;34m(bound_method, method_name, self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    269\u001b[0m   \u001b[0;34m\"\"\"Runs any method interceptors or the original method.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0minterceptor_stack\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mbound_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m   ctx = MethodContext(module=self,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/haiku/_src/recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, prev_state)\u001b[0m\n\u001b[1;32m    322\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"LSTM input must be rank-1 or rank-2.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m     \u001b[0mx_and_h\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprev_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m     \u001b[0mgated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_and_h\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider aligning the order of gates with Sonnet.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[0;31m# i = input, g = cell_gate, f = forget_gate, o = output_gate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/haiku/_src/module.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    419\u001b[0m           \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstateful\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocal_module_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 421\u001b[0;31m       \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m       \u001b[0;31m# Module names are set in the constructor. If `f` is the constructor then\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/haiku/_src/module.py\u001b[0m in \u001b[0;36mrun_interceptors\u001b[0;34m(bound_method, method_name, self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    269\u001b[0m   \u001b[0;34m\"\"\"Runs any method interceptors or the original method.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0minterceptor_stack\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mbound_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m   ctx = MethodContext(module=self,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/haiku/_src/basic.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, precision)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mstddev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m       \u001b[0mw_init\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTruncatedNormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstddev\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstddev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m     \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_parameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"w\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mw_init\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprecision\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/haiku/_src/base.py\u001b[0m in \u001b[0;36mget_parameter\u001b[0;34m(name, shape, dtype, init)\u001b[0m\n\u001b[1;32m    521\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m     raise ValueError(\n\u001b[0;32m--> 523\u001b[0;31m         \u001b[0;34mf\"{fq_name!r} with retrieved shape {param.shape!r} does not match \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    524\u001b[0m         f\"shape={shape!r} dtype={dtype!r}\")\n\u001b[1;32m    525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: 'lstm/linear/w' with retrieved shape (134, 512) does not match shape=[224, 512] dtype=dtype('float32')"
          ]
        }
      ],
      "source": [
        "network = hk.without_apply_rng(hk.transform(network_definition))\n",
        "zacharys_karate_club = get_zacharys_karate_club(s_graph)\n",
        "labels = get_ground_truth_assignments_for_zacharys_karate_club(GS1d)\n",
        "params = network.init(jax.random.PRNGKey(42), zacharys_karate_club)\n",
        "paramsA=params\n",
        "\n",
        "opt_init, opt_update = optax.adam(1e-2)\n",
        "opt_state = opt_init(params)\n",
        "\n",
        "for step in range(10):\n",
        "#     print(f\"step {step} accuracy {accuracy(params).item():.2f}\")\n",
        "    params, opt_state = update(params, opt_state)\n",
        "# predict(params)\n",
        "jnp.argmax(network.apply(params, zacharys_karate_club).nodes,axis=1)\n",
        "# output_graph = network.apply(params, input_graph)\n",
        "\n",
        "# result,params,netA = optimize_club(networkA, num_steps=10)\n",
        "\n",
        "# network = hk.without_apply_rng(hk.transform(network_definition))\n",
        "# input_graph = get_random_graph()\n",
        "# params = network.init(jax.random.PRNGKey(42), input_graph)\n",
        "# output_graph = network.apply(params, input_graph)\n",
        "# print(tree.tree_map(lambda x: x.shape, output_graph))\n",
        "\n",
        "\n",
        "# network = hk.without_apply_rng(hk.transform(network_definition))\n",
        "# # input_graph = get_random_graph()\n",
        "# zacharys_karate_club = get_zacharys_karate_club(s_graph)\n",
        "# params = network.init(jax.random.PRNGKey(42), zacharys_karate_club)\n",
        "\n",
        "# output_graph = network.apply(paramsA, zacharys_karate_club)\n",
        "# print(tree.tree_map(lambda x: x.shape, output_graph))\n",
        "\n",
        "# network = hk.without_apply_rng(hk.transform(network_definition))\n",
        "# output_graph = network.apply(params, netA)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7Cns9EITp0k"
      },
      "source": [
        "The final node assignment predicted by the trained model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0leRi5igUUyd"
      },
      "outputs": [],
      "source": [
        "zacharys_karate_club = get_zacharys_karate_club(s_graph)\n",
        "nx_graph = convert_jraph_to_networkx_graph(zacharys_karate_club)\n",
        "pos = nx.circular_layout(nx_graph)\n",
        "\n",
        "fig = plt.figure(figsize=(15, 7))\n",
        "ax1 = fig.add_subplot(121)\n",
        "nx.draw(\n",
        "    nx_graph,\n",
        "    pos=pos,\n",
        "    with_labels=True,\n",
        "    node_size=500,\n",
        "    node_color=result.tolist(),\n",
        "    font_color='white')\n",
        "ax1.title.set_text('Predicted Node Assignments with GAT')\n",
        "\n",
        "gt_labels = get_ground_truth_assignments_for_zacharys_karate_club(GS1d)\n",
        "ax2 = fig.add_subplot(122)\n",
        "nx.draw(\n",
        "    nx_graph,\n",
        "    pos=pos,\n",
        "    with_labels=True,\n",
        "    node_size=500,\n",
        "    node_color=gt_labels.tolist(),\n",
        "    font_color='white')\n",
        "ax2.title.set_text('Ground-Truth Node Assignments')\n",
        "fig.suptitle('Do you spot the difference? 😐', y=-0.01)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "lets add in LSTM to model to account for time\n",
        "\n",
        "[inspired by GRU then LSTM](https://colab.research.google.com/github/keras-team/keras-io/blob/master/examples/timeseries/ipynb/timeseries_traffic_forecasting.ipynb#scrollTo=hRpthm4r4j6a) | [and from googleBrain code here](https://github.com/deepmind/jraph/blob/master/jraph/examples/lstm.py)"
      ],
      "metadata": {
        "id": "PKiTfJEi5_rQ"
      }
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "DM_AXA_AE_JAX/jraph",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}