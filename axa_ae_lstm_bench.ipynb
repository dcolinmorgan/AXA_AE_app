{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92a03b9c-b6b7-4351-9e05-44a47941b2ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-16 15:30:34.648429: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-09-16 15:30:34.653008: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /cm/shared/apps/anaconda3-2021-05/lib:/cm/shared/apps/pbspro-ce/19.1.3/lib/\n",
      "2022-09-16 15:30:34.653028: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    "from numpy import concatenate\n",
    "from matplotlib import pyplot\n",
    "import pandas as pd, numpy as np, matplotlib.pyplot as plt\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7785362b-4435-4ad4-b4a7-210e583c7fbd",
   "metadata": {},
   "source": [
    "## inspiration [here](https://machinelearningmastery.com/multivariate-time-series-forecasting-lstms-keras/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49e973a1-da8d-4325-82ce-b1a25f6287f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert series to supervised learning\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
    "\tdf = DataFrame(data)\n",
    "\tcols, names = list(), list()\n",
    "\t# input sequence (t-n, ... t-1)\n",
    "\tfor i in range(n_in, 0, -1):\n",
    "\t\tcols.append(df.shift(i))\n",
    "\t\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# forecast sequence (t, t+1, ... t+n)\n",
    "\tfor i in range(0, n_out):\n",
    "\t\tcols.append(df.shift(-i))\n",
    "\t\tif i == 0:\n",
    "\t\t\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "\t\telse:\n",
    "\t\t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# put it all together\n",
    "\tagg = concat(cols, axis=1)\n",
    "\tagg.columns = names\n",
    "\t# drop rows with NaN values\n",
    "\tif dropnan:\n",
    "\t\tagg.dropna(inplace=True)\n",
    "\treturn agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde6b06b-571e-4d3c-b2c4-5d8b2094a30c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6804e01f-3d93-48b0-967a-ee4d11bef274",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ld_data(data,n_days,frac):\n",
    "\n",
    "    dataset=data.values\n",
    "\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled = scaler.fit_transform(dataset)\n",
    "\n",
    "    x_scaled = scaled[:,:data.shape[1]-1].astype('float32') #.drop('diag1',axis=1).values.astype('float32')\n",
    "    y_scaled = scaled[:,data.shape[1]-1:].astype('float32') #['diag1'].values.astype('float32')\n",
    "    # integer encode direction\n",
    "    encoder = LabelEncoder()\n",
    "    # values[:,4] = encoder.fit_transform(values[:,4])\n",
    "    # ensure all data is float\n",
    "    # values = values.astype('float32')\n",
    "    # normalize features\n",
    "\n",
    "\n",
    "    # y_scaled = scaler.fit_transform(y_values)\n",
    "\n",
    "    # specify the number of lag days\n",
    "    n_days = 7\n",
    "    n_features =  x_scaled.shape[1]\n",
    "    # frame as supervised learning\n",
    "\n",
    "    x_reframed = series_to_supervised(x_scaled, n_days, 1).values\n",
    "    y_reframed = y_scaled #series_to_supervised(y_scaled, n_days, 1).values\n",
    "    y_reframed = y_reframed[:x_reframed.shape[0]]\n",
    "    # print(reframed.shape)\n",
    "\n",
    "    # drop=np.arange(n_features+1,(2*n_features),1)\n",
    "    # reframed.drop(reframed.columns[drop], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "    # split into train and test sets\n",
    "    # values = reframed.values\n",
    "\n",
    "    n_train_days = 365 * round((len(x_scaled)/365)*.5) #* 24\n",
    "    n_obs = n_days * n_features\n",
    "    train_X = x_reframed[:n_train_days, :]\n",
    "    test_X = x_reframed[n_train_days:, :]\n",
    "\n",
    "    train_y = y_reframed[:n_train_days]\n",
    "    test_y = y_reframed[n_train_days:]\n",
    "\n",
    "    # split into input and outputs\n",
    "\n",
    "    train_X = train_X[:, :n_obs]#, train_y[:n_obs]\n",
    "    test_X = test_X[:, :n_obs]#, test_y[:n_obs]\n",
    "\n",
    "    # print(train_X.shape, len(train_X), train_y.shape)\n",
    "    # reshape input to be 3D [samples, timesteps, features]\n",
    "    train_X = train_X.reshape((train_X.shape[0], n_days, n_features))\n",
    "    test_X = test_X.reshape((test_X.shape[0], n_days, n_features))\n",
    "    print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)\n",
    "    \n",
    "    \n",
    "    return train_X, train_y,test_X,test_y,n_features,scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fd1c334-11cc-433e-96e9-42ae2a440f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_mdl(train_X, train_y,test_X,test_y,YY,var,site,n_days,n_features,scaler):\n",
    "    # design network\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mae', optimizer='adam')\n",
    "    # fit network\n",
    "    if YY=='shuf':\n",
    "        train_y=np.random.permutation(train_y)\n",
    "    elif YY=='orig':\n",
    "        train_y=train_y\n",
    "\n",
    "    history = model.fit(train_X, train_y, epochs=50, batch_size=72, validation_data=(test_X, test_y), verbose=0, shuffle=True)\n",
    "\n",
    "    # plot history\n",
    "    pyplot.plot(history.history['loss'], label='train')\n",
    "    pyplot.plot(history.history['val_loss'], label='test')\n",
    "    pyplot.legend()\n",
    "    pyplot.title(var+'_'+YY+'_loss_'+site)\n",
    "    # pyplot.show()\n",
    "    plt.savefig('NNtest/'+var+'_'+YY+'_loss_'+site+'.png')\n",
    "    plt.clf()\n",
    "    \n",
    "    # make a prediction\n",
    "    yhat = model.predict(test_X)\n",
    "    \n",
    "    test_X2 = test_X.reshape((test_X.shape[0], n_days*n_features))\n",
    "    # # invert scaling for forecast\n",
    "    inv_yhat = concatenate((yhat, test_X2[:, -(n_features):]), axis=1)\n",
    "    inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "    inv_yhat = inv_yhat[:,0]\n",
    "    # invert scaling for actual\n",
    "\n",
    "\n",
    "    test_y2 = test_y.reshape(test_y.shape[0]*test_y.shape[1])\n",
    "    inv_y = concatenate((test_y, test_X2[:, -(n_features):]), axis=1)\n",
    "    inv_y = scaler.inverse_transform(inv_y)\n",
    "    inv_y = inv_y[:,0]\n",
    "\n",
    "    print([inv_yhat.shape,test_y2.shape,inv_y.shape])\n",
    "\n",
    "    # calculate MSE\n",
    "    mse = (mean_squared_error(inv_y, inv_yhat))\n",
    "    print('Test MSE: %.3f' % mse)\n",
    "\n",
    "    plt.plot(np.rint(inv_y), alpha = .5,label='pred')\n",
    "    plt.plot(np.double(inv_yhat), alpha = .5,label='valid')\n",
    "    plt.title(site+'_'+var+'_'+YY+ 'MSE: '+str(mse))\n",
    "    plt.legend()\n",
    "    plt.savefig('NNtest/'+site+'_'+var+'_'+YY+'_mse.png')\n",
    "    plt.clf()\n",
    "    return mse\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4bd94a7-bb67-485f-90b4-1c302e7976ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1095, 7, 8) (1095, 1) (786, 7, 8) (786, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-16 15:30:36.608054: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-09-16 15:30:36.608096: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (hpc-hn001): /proc/driver/nvidia/version does not exist\n",
      "2022-09-16 15:30:36.608424: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 0s 1ms/step\n",
      "[(786,), (786,), (786,)]\n",
      "Test MSE: 218.641\n",
      "QEH_all_origMSE: 218.64139\n",
      "(1095, 7, 8) (1095, 1) (786, 7, 8) (786, 1)\n",
      "25/25 [==============================] - 0s 2ms/step\n",
      "[(786,), (786,), (786,)]\n",
      "Test MSE: 219.786\n",
      "QEH_all_shufMSE: 219.7857\n",
      "(1095, 7, 2) (1095, 1) (837, 7, 2) (837, 1)\n",
      "27/27 [==============================] - 0s 2ms/step\n",
      "[(837,), (837,), (837,)]\n",
      "Test MSE: 215.662\n",
      "QEH_ae_origMSE: 215.66241\n",
      "(1095, 7, 2) (1095, 1) (837, 7, 2) (837, 1)\n",
      "27/27 [==============================] - 0s 2ms/step\n",
      "[(837,), (837,), (837,)]\n",
      "Test MSE: 216.603\n",
      "QEH_ae_shufMSE: 216.60258\n",
      "(1095, 7, 8) (1095, 1) (786, 7, 8) (786, 1)\n",
      "25/25 [==============================] - 0s 1ms/step\n",
      "[(786,), (786,), (786,)]\n",
      "Test MSE: 219.655\n",
      "QEH_poll_origMSE: 219.65489\n",
      "(1095, 7, 8) (1095, 1) (786, 7, 8) (786, 1)\n",
      "25/25 [==============================] - 0s 2ms/step\n",
      "[(786,), (786,), (786,)]\n",
      "Test MSE: 218.729\n",
      "QEH_poll_shufMSE: 218.72879\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "var_list = []\n",
    "mse_list = []\n",
    "site_list = []\n",
    "order_list = []\n",
    "\n",
    "for i in ['all','ae','poll']:\n",
    "    for SS in ['orig','shuf']:\n",
    "        data=pd.read_parquet('~/run/AXA_AE_app/AE_AXA_poll-ae.parquet')#, compression='GZIP')#.mode('overwrite')\n",
    "        data=data[data['cd9_loc']=='Queen Elizabeth Hospital']\n",
    "        site='QEH'\n",
    "        data=data.groupby(['cd9_loc','date']).agg('mean')[['pm25','pm10','o3','no2','so2','co','age','sex','diag1']]\n",
    "        # data=data.groupby(['date']).agg('mean')[['pm25','pm10','o3','no2','so2','co','age','sex','diag1']]\n",
    "\n",
    "        # data=data.groupby(['date']).agg({'pm25':'mean','pm10':'mean','o3':'mean','no2':'mean','so2':'mean','co':'mean','age':'mean','sex':'mean','diag1':'mean'})\n",
    "        data.age=np.round(data.age)\n",
    "        data.sex=np.round(data.sex)\n",
    "        # first_column = data.pop('diag1') ## comment for avg all loc\n",
    "        # data.insert(0, 'diag1', first_column) ## comment for avg all loc\n",
    "\n",
    "        # values = dataset.values\n",
    "        first_column = data.pop('diag1')\n",
    "        data.insert(0, 'diag1', first_column)\n",
    "        if i=='all':\n",
    "            data=data\n",
    "        elif i=='ae':\n",
    "            data=data[['diag1','age','sex']]\n",
    "        elif i =='poll':\n",
    "            data[['diag1','pm25','pm10','o3','no2','so2','co']]#drop(['age','sex'],axis=1,inplace=True)\n",
    "        n_days=7\n",
    "        train_X, train_y,test_X,test_y,n_features,scaler=ld_data(data,n_days,.7)\n",
    "        mse=run_mdl(train_X, train_y,test_X,test_y,SS,i,site,n_days,n_features,scaler)\n",
    "        \n",
    "        var_list.append(i)\n",
    "        mse_list.append(mse)\n",
    "        site_list.append(site)\n",
    "        order_list.append(SS)\n",
    "        print(site+'_'+i+'_'+SS+ 'MSE: '+str(mse))\n",
    "        \n",
    "df = pd.DataFrame(list(zip(var_list , mse_list,site_list,order_list)), \n",
    "           columns =['var', ',mse','site','order'])\n",
    "\n",
    "df.to_csv('NNtest/NN_mse.txt',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bce634-90ba-4200-b182-e39e3dd9dd6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mypy38",
   "language": "python",
   "name": "mypy38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
